The aim of this methodology review was to assess whether the time taken to publish the results of clinical trials is influenced by the statistical significance of their results (time‚Äêlag bias). If clinical trials with positive findings are stopped earlier than planned and published quicker than those trials with null or negative findings, then new interventions might be mistakenly assumed to be effective. Two studies with a total of 196 trials met the inclusion criteria for this review. In both studies just over half of the trials had been published in full. Trials with positive results (i.e. with statistically significant results in favour the experimental arm of the trial) tended to be published in approximately 4 to 5 years. Trials with null or negative results (i.e. not statistically significant or statistically significant in favour of the control arm) were published after about 6 to 8 years. One of the studies suggested that this difference could, in part, be attributed to the length of time taken to publish the results of a trial once follow up has been completed. This study showed that trials with null or negative findings took, on average, just over a year longer to be published than those with positive results. Our review shows that trials with positive results are published sooner than those with null or negative results. This has important implications for the timing of the initiation and updating of a systematic review, especially if there is an association between the inclusion of a trial in a review and its publication status. It is of particular concern when one considers reviews containing only a small number of studies. 